{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a54cecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import requests\n",
    "import re\n",
    "driver = webdriver.Chrome(executable_path = r'C:\\ChromeWebDriver\\chromedriver.exe')\n",
    "Links = []\n",
    "LinksIndex = 0\n",
    "for bedrooms in range(1,7):\n",
    "    if bedrooms==6:\n",
    "        bedrooms = '>5'\n",
    "    url = f'https://www.magicbricks.com/property-for-sale/residential-real-estate?bedroom={bedrooms}&proptype=Multistorey-Apartment,Builder-Floor-Apartment,Penthouse,Studio-Apartment&cityName=Mumbai'\n",
    "    driver.get(url)\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    while True:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(2)\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(5)\n",
    "            new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "    webpage = driver.page_source\n",
    "    HTMLPage = BeautifulSoup(webpage, 'html.parser')\n",
    "    LinkIndexes = [m.start() for m in re.finditer('https://www.magicbricks.com/propertyDetails/', webpage)]\n",
    "    for index in LinkIndexes:\n",
    "        Links.append('')\n",
    "        for urlindex in range(index,index+200):\n",
    "            if webpage[urlindex] == '\"':\n",
    "                break\n",
    "            else:\n",
    "                Links[LinksIndex] += webpage[urlindex]\n",
    "        LinksIndex+=1\n",
    "Links = list(set(Links))\n",
    "Prices = []\n",
    "Area = []\n",
    "Locations = []\n",
    "Amenities = []\n",
    "Bedrooms = []\n",
    "driver.close()\n",
    "Amenities_List = ['Reserved Parking','Lift','Power Back Up','Piped Gas','Park','Kids play area','Gymnasium','Swimming Pool',\n",
    "                  'Club House','Air Conditioned','Internet/Wi-Fi Connectivity']\n",
    "async def scraping(url,session):\n",
    "    async with session.get(url) as page:\n",
    "        try:\n",
    "            page1 = await page.text()\n",
    "            HTMLPage = BeautifulSoup(page1, 'html.parser')\n",
    "            price = HTMLPage.find(class_='mb-ldp__dtls__price').text\n",
    "            pagesqft = HTMLPage.find(class_='mb-ldp__dtls__body__list')\n",
    "            areaindex = pagesqft.text.find('Area')\n",
    "            sqftindex = pagesqft.text.find('sqft')\n",
    "            sqft = ''\n",
    "            for index in range(areaindex,sqftindex+4):\n",
    "                sqft+=pagesqft.text[index]\n",
    "            sqft = sqft[4:]\n",
    "            pagelocation = HTMLPage.find_all(class_='mb-ldp__more-dtl__list--value')\n",
    "            for text in pagelocation:\n",
    "                text = text.text\n",
    "                if 'Mumbai' in text:\n",
    "                    location = text\n",
    "            amenities = ''\n",
    "            for Amenity in Amenities_List:\n",
    "                if Amenity in page1:\n",
    "                    amenities += Amenity + ','\n",
    "            pageBHK = HTMLPage.find(class_='mb-ldp__dtls__title--text1--text')\n",
    "            pageBHK = pageBHK.text\n",
    "            BHKIndex = pageBHK.find('BHK')\n",
    "            BHK = ''\n",
    "            for index in range(BHKIndex-2,BHKIndex+3):\n",
    "                BHK+=pageBHK[index]\n",
    "            Area.append(sqft)\n",
    "            Prices.append(price)\n",
    "            Amenities.append(amenities)\n",
    "            Bedrooms.append(BHK)\n",
    "            Locations.append(location)\n",
    "        except:\n",
    "            pass\n",
    "async def main():\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = [await scraping(url,session) for url in Links]\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da441d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'Price': pd.Series(Prices),\n",
    "                  'Location': pd.Series(Locations),\n",
    "                  'Area': pd.Series(Area),\n",
    "                  'Amenities':pd.Series(Amenities),\n",
    "                  'BHK': pd.Series(Bedrooms)})\n",
    "df.to_csv('HousePrices.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
